{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNE08xVgDsW8",
        "colab_type": "text"
      },
      "source": [
        "# Update and install libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOlKbEYrtUFr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install gdown\n",
        "!pip install gast==0.2.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AwSTCefD1OV",
        "colab_type": "text"
      },
      "source": [
        "# Download model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hqlPIb6ueEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gdown https://drive.google.com/uc?id=1VeItsWR5Pn6udTHiokWmLqt6StcyT2k5\n",
        "!gdown https://drive.google.com/uc?id=10d8qcSGxGS5xEHYDoWvoUw87g0_QoJoq\n",
        "!gdown https://drive.google.com/uc?id=10W5F7XO5gkzpxGalo2qgD_Ffzn3uhNO-\n",
        "!gdown https://drive.google.com/uc?id=10cQBEnrMXM2T3vmBW0GIcWgHC2V3tofe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lbqc-wm_D-pY",
        "colab_type": "text"
      },
      "source": [
        "# Upload images\n",
        "If these codelines crush, just execute them again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_zaSzifwOft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "ts_urls = []\n",
        "for x in uploaded:\n",
        "  ts_urls.append(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxdF7UHIEQ3E",
        "colab_type": "text"
      },
      "source": [
        "# Select tensorflow 2.x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSNcaMkHKlEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu5eDLZtEUJ7",
        "colab_type": "text"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF6J4Tcg1vQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.layers import *\n",
        "\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjERF-B-EkxO",
        "colab_type": "text"
      },
      "source": [
        "# Create test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlsRPjL2381n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "\n",
        "# Reescalar imagenes.\n",
        "def resize(inimg, height, width):\n",
        "  inimg = tf.image.resize(inimg, [height, width])\n",
        "  return inimg\n",
        "\n",
        "#Normalizas al rango [-1, +1] la imagen\n",
        "def normalize(inimg):\n",
        "  inimg = (inimg / 127.5) - 1\n",
        "  return inimg\n",
        "\n",
        "# Aumentación de datos : Random Crop + Flip\n",
        "def random_jitter(inimg):\n",
        "  inimg = resize(inimg, 286, 286)\n",
        "  \n",
        "  stacked_image = tf.stack([inimg], axis=0)\n",
        "  cropped_image = tf.image.random_crop(stacked_image, size=[1, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "  \n",
        "  inimg = cropped_image[0]\n",
        "  \n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    inimg = tf.image.flip_left_right(inimg)\n",
        "  return inimg\n",
        "\n",
        "@tf.function\n",
        "def load_image(filename, augment=True):\n",
        "  inimg = tf.cast(tf.image.decode_jpeg(tf.io.read_file(filename)), tf.float32)[..., :3]\n",
        "  \n",
        "  inimg = resize(inimg,IMG_HEIGHT, IMG_WIDTH)\n",
        "  \n",
        "  if augment:\n",
        "    inimg = random_jitter(inimg)\n",
        "  \n",
        "  inimg = normalize(inimg)\n",
        "  \n",
        "  return inimg\n",
        "\n",
        "\n",
        "def load_test_image(filename):\n",
        "  return load_image(filename, False)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(ts_urls)\n",
        "test_dataset = test_dataset.map(load_test_image, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "097qR5OmE2xM",
        "colab_type": "text"
      },
      "source": [
        "# Create generator model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6APXet6OVIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def downsample(filters, apply_batchnorm=True):\n",
        "  \n",
        "  result = Sequential()\n",
        "  \n",
        "  initializer = tf.random_normal_initializer(0, 0.02)\n",
        "  \n",
        "  # Capa convulocional\n",
        "  result.add(Conv2D(filters, \n",
        "                    kernel_size = 4,\n",
        "                    strides = 2,\n",
        "                    padding = \"same\",\n",
        "                    kernel_initializer= initializer,\n",
        "                    use_bias=not apply_batchnorm))\n",
        "  \n",
        "  # Capa de BatchNorm.\n",
        "  if apply_batchnorm:\n",
        "    result.add(BatchNormalization())\n",
        "  \n",
        "  # Capa de activación.\n",
        "  result.add(LeakyReLU())\n",
        "  \n",
        "  return result\n",
        "\n",
        "downsample(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBH3UGqj2m-y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(filters, apply_dropout=False):\n",
        "  \n",
        "  result = Sequential()\n",
        "  \n",
        "  initializer = tf.random_normal_initializer(0, 0.02)\n",
        "  \n",
        "  # Capa convulocional\n",
        "  result.add(Conv2DTranspose( filters, \n",
        "                              kernel_size = 4,\n",
        "                              strides = 2,\n",
        "                              padding = \"same\",\n",
        "                              kernel_initializer= initializer,\n",
        "                              use_bias=False))\n",
        "  \n",
        "  # Capa de BatchNorm.\n",
        "  result.add(BatchNormalization())\n",
        "  \n",
        "  # Capa de Dropout\n",
        "  if apply_dropout:\n",
        "    result.add(Dropout(0.5))\n",
        "  \n",
        "  # Capa de activación.\n",
        "  result.add(ReLU())\n",
        "  \n",
        "  return result\n",
        "\n",
        "upsample(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-qC28vH3a5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Generator():\n",
        "  \n",
        "  inputs = tf.keras.layers.Input(shape=[None, None, 3])\n",
        "  \n",
        "  down_stack = [\n",
        "      downsample(64, apply_batchnorm=False), # (bs, 128, 128, 64)\n",
        "      downsample(128),                       # (bs, 64,  64,  128)\n",
        "      downsample(256),                       # (bs, 32,  32,  256)\n",
        "      downsample(512),                       # (bs, 16,  16,  512)\n",
        "      downsample(512),                       # (bs, 8,   8,   512)\n",
        "      downsample(512),                       # (bs, 4,   4,   512)\n",
        "      downsample(512),                       # (bs, 2,   2,   512)\n",
        "      downsample(512)                        # (bs, 1,   1,   512)\n",
        "  ]\n",
        "  \n",
        "  up_stack = [\n",
        "      upsample(512, apply_dropout=True),     # (bs, 2,   2,   512)\n",
        "      upsample(512, apply_dropout=True),     # (bs, 4,   4,   512)\n",
        "      upsample(512, apply_dropout=True),     # (bs, 8,   8,   512)\n",
        "      upsample(512),                         # (bs, 16,  16,  512)\n",
        "      upsample(256),                         # (bs, 32,  32,  256)\n",
        "      upsample(128),                         # (bs, 64,  64,  128)\n",
        "      upsample(64),                          # (bs, 128, 128, 64)\n",
        "  ]\n",
        "  \n",
        "  \n",
        "  initializer = tf.random_normal_initializer(0, 0.02)\n",
        "  \n",
        "  last = Conv2DTranspose(filters = 3,\n",
        "                        kernel_size = 4,\n",
        "                        strides = 2,\n",
        "                        padding = \"same\",\n",
        "                        kernel_initializer= initializer,\n",
        "                        activation = \"tanh\")\n",
        "  \n",
        "  x = inputs\n",
        "  s = [] #skip conections\n",
        "  \n",
        "  concat = Concatenate()\n",
        "  \n",
        "  for down in down_stack:\n",
        "    x = down(x)\n",
        "    s.append(x)\n",
        "    \n",
        "  s = reversed(s[:-1])\n",
        "    \n",
        "  for up, sk in zip(up_stack, s):\n",
        "    \n",
        "    x = up(x)\n",
        "    x = concat([x, sk])\n",
        "  \n",
        "  last = last(x)\n",
        "  \n",
        "  return Model(inputs = inputs, outputs = last)\n",
        "\n",
        "generator = Generator()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9jfr3lqFAse",
        "colab_type": "text"
      },
      "source": [
        "# Load model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBkr4RP8OEe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "generator_optimizer     = tf.keras.optimizers.Adam(2e-4, beta_1 = 0.5)\n",
        "\n",
        "checkpoint_prefix = os.path.join(\"\", \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer = generator_optimizer,\n",
        "                                generator = generator)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(\"\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZPpFiHWFFhZ",
        "colab_type": "text"
      },
      "source": [
        "# Generate images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3rAe4iNPRqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_images(model, test_input,save_filename = False, display_imgs = True):\n",
        "\n",
        "  prediction = model(test_input, training=True)\n",
        "  \n",
        "  plt.figure(figsize=(10,10))\n",
        "\n",
        "  display_list = [test_input[0],  prediction[0]]\n",
        "  title = ['Input Image',  'Predicted Image']\n",
        "  \n",
        "  if display_imgs:\n",
        "    for i in range(2):\n",
        "      plt.subplot(1, 2, i+1)\n",
        "      plt.title(title[i])\n",
        "      # getting the pixel values between [0, 1] to plot it.\n",
        "      plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "      plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hro73v5IFlM2",
        "colab_type": "text"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyllRcrj6zsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for inp in test_dataset:\n",
        "      generate_images(generator, inp, False, display_imgs=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}